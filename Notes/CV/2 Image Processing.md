
## Histogram Equalization

直接拍照得到的图像往往灰度值或各 RGB 值的分布是不均匀的，很可能集中在某个区间内，导致图像对比度较低，我们想让其分布变得更均衡，最好是变成均匀分布

![[CV/img/img2/image.png]]

假设现有随机变量 $X$ ，其 **累积分布函数 cumulative distribution function (CDF)** 定义如下

$$F(x)=P(X\leq x)$$

设 $y=F(x)$  ，则我们取 $y$ 上的一个均匀分布，可以通过 $F^{-1}$ 的作用得到 $x$ 服从的分布（这也是如何得到一个服从特定分布的随机数的方法），那么反过来，对于 $x$ ，我们可以根据其分布计算出 $F$ ，那么 $y=F(x)$ 就服从均匀分布了

![[CV/img/img2/image-1.png]]

对于图像，以灰度图为例，先根据每个灰度值有多少个像素计算出其 CDF ，再把每个像素的灰度值 $x$ 换为 $255 \times CDF(x)$ （灰度值区间设为 $[0,255]$ ），这样变换后，其灰度值就服从均匀分布了，即各个灰度值对应的像素数量基本相同

# Filter

## Liner Filtering

线性滤波就是拿一个 kernel 在图像上做卷积（需要 padding 保证大小不变）

>严格的讲，这里的卷积实际上是数学上的相关性计算，而数学上的卷积要先翻转卷积函数/卷积核

![[CV/img/img2/image-2.png]]

### Gaussian Filter

高斯滤波是一种低通 low-pass 滤波，即倾向于保留低频信号，抑制高频信号，能模糊图像，让图像更平滑连贯，其卷积核可以用以下计算方式得出
- 先通过高斯分布得到一个向量 $x=[x_1,...,x_k]$
- 卷积核的矩阵 $K=x^Tx$ ，而后进行归一化使得元素总和为 1 

在 filter 中做归一化是有必要的，比如以下模板匹配 Template Matching 的任务，即给定一个模板样式（比如一个局部图像或轮廓），在一张图片上找到与其最相似的区域
如果直接利用滑窗计算各个区域的相关性，会导致结果受到这个区域的像素值的影响（比如明暗程度），所以需要归一化

![[CV/img/img2/image-9.png]]

### Sharpening Filter

![[CV/img/img2/image-3.png]]

## Non-Linear Filtering

### Median Filter

有些情况线性滤波解决不了，比如椒盐噪声 Salt and Pepper Noise ，如果用高斯滤波处理就变成这样，根本没啥用

![[CV/img/img2/image-4.png]]

可以采用中值滤波，对于卷积核范围内的像素，将其像素值排序，取其中值作为这个像素的卷积结果，这使得某个像素的像素值变得与其邻居相同，非常适合处理一些非连续的、散点式分布的噪音（脉冲式噪音 impulse noise）

![[CV/img/img2/image-5.png]]

### Bilateral Filter

对于另一些情况，我们想消除噪声，但还想保留原来的边缘和纹理，而高斯噪声一下子都给整没了

![[CV/img/img2/image-6.png]]

这是因为高斯滤波只是简单考虑了空间上的距离，靠近中心的权重大，远离中心的权重小，但根本没考虑”内容”方面的信息

双边滤波在此基础上引入了另一个权重，两个权重综合作用进行滤波
- Domain Kernel ：衡量与中心像素的距离，这是一个高斯核，越靠近中心权重越大

$$W_d(i, j) = \exp\left(-\frac{{(x_i - x)}^2 + {(y_i - y)}^2}{2\sigma_d^2}\right)$$

- Range Kernel ：衡量与中心像素的灰度/颜色相似程度，越相似权重越大

$$W_r(i, j) = \exp\left(-\frac{{(I(x_i, y_i) - I(x, y))}^2}{2\sigma_r^2}\right)$$

最终的结果由这两个卷积核共同作用得到

$$
I_{\text{filtered}}(x, y) = \frac{1}{W_{\text{total}}} \sum_{x_i, y_i \in \Omega} I(x_i, y_i) \cdot \underbrace{W_d(i, j)}_{\text{空间权重}} \cdot \underbrace{W_r(i, j)}_{\text{值域权重}}
$$

![[CV/img/img2/image-7.png]]

此外，双边滤波还有一些消除噪声之外的作用，比如把图片变成卡通风格

![[CV/img/img2/image-8.png]]

### Joint Bilateral Filter

在较昏暗的场景拍照时，如果不开闪光灯 flash ，由于曝光时长等原因会导致噪声太大，但是如果开了闪光灯，虽然能保留纹理，但会失去原来的色调，利用双边滤波，就可以将二者的内容整合，保留原有色调的基础上消除噪声

![[CV/img/img2/image-10.png]]

为此，可以对双边滤波进行一些调整，在计算值域相似性时，不直接将 Range Kernel 作用于待处理的图像，而是作用于另一张纹理更清晰的参考图像，这就是 **联合双边滤波**

具体流程如下，我们对 Flash Image 进行双边滤波，再将原图像的各像素值除以滤波后的图像的各像素值，得到了一层记录细节信息的 mask ；对 No-Flash Image 进行联合双边滤波，参考图像为 Flash Image ，而后将 mask 乘到滤波后的图像上，就得到了最终结果

![[CV/img/img2/image-11.png]]

>对于 mask ，不采用加减的方式是因为容易被像素值范围截断

# Upsampling / Downsampling Pyramid

## Downsampling and Gaussian Pyramid

我们想缩小图片，比如缩小到原来的 1/2 ，这个过程就是 **降采样** ，一个简单的想法是保留行和列索引为 0 2 4 ... 处的像素值，但这么做会导致图像失真，这被称为 **走样 Aliasing**

![[CV/img/img2/image-12.png]]

解决办法很简单，每次降采样前先进行高斯滤波

![[CV/img/img2/image-13.png]]

如果把这一系列高斯滤波+降采样的操作连在一起，就形成了 **高斯金字塔** ，其中每一步都将图像缩小 1/2

![[CV/img/img2/image-14.png]]
​​
## Upsampling

降采样的逆过程是 **上采样** ，也就是要放大图片，但是放大后会多出来很多像素，需要填充这些像素，一种简单的方法是 **最近邻插值 nearest neighbor interpolation** ，即直接取离得最近的原图像中的像素的值，但结果太烂了

![[CV/img/img2/image-15.png]]
我们需要考虑其它的插值方式，以下是一些基本的插值方式及其基函数

![[CV/img/img2/image-16.png]]
在图像中，由于是二维的，需要进行双线性插值，值得注意的是双线性插值并不是线性的，因为表达式中含有 $xy$ 项，对于图片，有一种很方便的计算方法，即对四个点直接加权求和，权重是各自对应的矩形面积

![[CV/img/img2/image-17.png]]

在双线性插值中，有两种方式，即要不要把角落对齐

![[CV/img/img2/image-18.png]]

- 角落对齐：目标图像的像素在源图像中均匀对齐到对应的角点，插值结果能保留角落与边缘，可用于超分辨率图像重建
- 角落不对齐：目标图像的像素更多地集中在源像素格网的中间，插值更加平滑，但不会严格对齐两端，可用于深度学习特征映射操作（如上采样层），因为它避免了边界处的特征失真和数值偏移问题，更平滑地处理非连续场景

### Joint Bilateral Upsampling

假设现在有一个高分辨率图像，想要得到对应的深度图，如果直接进行计算或者预测，由于分辨率很高，计算量会非常大，考虑先降采样，对这个缩小后的图片计算深度图，再上采样回去

如果直接使用上述基本的插值方式进行上采样，得到的结果要么被像素化（最近邻插值），要么过于平滑（这并不一定是理想的，因为深度是可能突变的，比如对于遮挡物体的边缘处）

别忘了我们还有一个高分辨率的原图像，可以利用其特征信息对这个低分辨率的深度图进行上采样，可以使用联合双边滤波来进行插值

要进行插值，就得先算出基函数，也就是对于一个待插值点，计算各个数据点在此处的权重，参考联合双边滤波，这可以分为两部分：一部分是空间差异，即插值点到数据点的距离；另一部分是取值差异，即参考的高分辨率图像上插值点处和数据点处的颜色差异

各种插值方式得到的结果如下，可见联合双边上采样很好的保留了边缘特征与深度变化的信息

![[CV/img/img2/image-19.png]]

### Laplacian Pyramid

通过高斯金字塔得到了一系列缩小后的图片，现在要从缩小的图片逐渐恢复到原来的分辨率

以第 4 层为例，先对于 G4 的图片进行上采样（一般先插零，再利用一个放大的高斯核卷积），而后将 G3 的图片与 G4 上采样的图片做差，得到一个特征图 L3 ，在恢复时，只需将 G4 的图片与 L3 相加

![[CV/img/img2/image-20.png]]

为了简化计算，可以直接将 G3 进行高斯模糊，再做差得到 L3 ，得到的结果可能略有差别，因为这忽略了高斯模糊后的先降采样再上采样带来的失真

---

那这跟拉普拉斯有啥关系？拉普拉斯每一层的计算相当于计算两层高斯金字塔的差距，这个过程是在用 高斯函数的差 Difference of Gaussian (DoG) 去近似 高斯函数的拉普拉斯 Laplacian of Gaussian (Log) 

拉普拉斯算子 $\nabla$ 定义为

$$\nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}$$

而高斯函数定义为

$$G(x, y; \sigma) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}}$$

可以通过推导得到

$$G(x, y, k\sigma) - G(x, y, \sigma) \approx (k - 1) \sigma^2 \nabla^2 G$$

由于高斯滤波是低通滤波，两个高斯滤波的差距就是保留中间一段频率的滤波，这称为 带通滤波 band-pass filter

---

我们想还原高分辨率图像，但拉普拉斯金字塔的还原过程却要用到高分辨率图像，这看似是个伪命题，但在一些场景下还是有用的

比如说我们要在云端渲染一个高分辨率图片，如果直接传输可能得很长时间才能加载所有部分，但使用拉普拉斯金字塔，我们可以先传一个低分辨率的过去，这很好显示，然后再传一个特征图过去，这个特征图一般是稀疏的，比直接传高分辨率图效率更高，这就能逐步恢复图像了，而且不是一部分一部分渲染，而是从模糊到清晰

此外，在图片的混合渲染中也有应用
### Image Blending

假设我们扣了一个图，把它粘到另一个图上，直接放上去差距太大了，我们希望让边缘和色调的过渡更平滑，但又要保留扣的图的细节

![[CV/img/img2/image-21.png]]

可以利用高斯和拉普拉斯金字塔，对于 mask ，构建高斯金字塔，应用到每一层上；对于两个图像，构建拉普拉斯金字塔，并利用高斯模糊后的 mask 计算每一层混合后的特征图，这能滤掉边缘处的剧烈变化，而保留了各自图像内部的细节信息

在恢复时，先把低分辨率的图像混合，由于分辨率很低，这个图像是非常平滑的，而后逐步补充细节信息

![[CV/img/img2/image-22.png]]

最后得到的结果如下

![[image-23.png]]

# Image Transformation

## Image Warping

对于一个图片，还能对其进行形状上的变换

![[image-24.png]]

要得到变换后的图片，一个简单的想法是把原图中的每个像素直接复制到变换后的位置，这称为 **Forward Warping** ，但缺点很明显，如果某处存在压缩，就会产生重叠，即原图多个像素都变换到一个地方；如果某处存在拉伸，就会产生空洞，即原图像素变换后无法完全覆盖，只能等都变换完之后通过插值弥补空洞的地方

另一种想法是对变换后的图像中的像素进行逆变换，找到其在原图中对应的坐标，而后根据这个坐标进行插值，计算应该填充的像素值，这称为 **Inverse Warping**

## Image Morphing

我们想把两个图片融合到一块，比如两个人脸捏成一个，但两个人脸形状不一样，不能直接叠加，不然会产生重影

![[image-25.png]]

为此，需要先标注出两个图片对应的特征点（比如都标注出眼角、嘴角、面部轮廓的点位），而后根据这些点将图片分为若干三角形区域（图像三角化），对于两个对应区域的三角形，把其顶点坐标和内部的像素值进行加权平均，就得到了结果图像上的一个三角区域的样子

![[image-26.png]]







