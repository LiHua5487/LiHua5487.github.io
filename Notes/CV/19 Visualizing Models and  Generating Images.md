
# Visualize Weights

想要将神经网络内部权重进行可视化，方便理解里面发生了什么过程，一种最直接的方法是，如果权重 channel 数正好是 3 ，那就可以把它们视为 RGB 通道，进行叠加，而后排列起来（batch 维度相当于有多少个权重图像，比如 64 个就按 8×8 排列）

下面是一些网络的第一层，这些权重与 edge / blob 特征提取的算子很类似，可见神经网络一开始会学习提取一些基本特征

![[CV/img/img19/image.png]]

如果 channel 数不是 3 ，那就直接视为一堆灰度图罗列出来，比如下图中一个括号里就是 C 个 H×W 的图像，共有 N 个括号

![[CV/img/img19/image-1.png]]

---

还可以根据最后提取出的特征向量（输入到分类器的那个向量），找到最近邻的输入图像，相比于直接逐像素对比找到的最近邻图像，利用特征向量找到的图像会有更强的语义相关性

![[CV/img/img19/image-2.png]]

# Visualize Parts of Interest

## Maximally Activating Patches

- 选择模型的某一层，和该中想要可视化的一个通道
- 输入很多图像给模型，记录下前向过程中，输入图像在经过模型的这一层后，得到的对应通道的特征图像上的值（称为“激活值”）
- 找到激活值最高的区域，对应回输入图像上，这就代表着输入图像中能让模型中这一层的这个通道最“兴奋”的部分（即响应最高的部分）

![[CV/img/img19/image-3.png]]

可以发现，前几层主要关注简单的局部纹理或局部图案；而深层会关注高层次特征或物体对象

## Saliency via Occlusion

另一种方法是，把输入图像中的一部分挡上，看模型输出的概率变了多少，如果变得多，说明对挡上的部分感兴趣，就把原图像这部分区域标记为高亮部分（红色）

![[CV/img/img19/image-4.png]]

可见相对于图像中的背景部分，模型往往更对物体感兴趣

## Saliency via Back Propagation

还可以利用反向传播，计算关于 class score （归一化之前的向量，如 softmax 之前的 logits）的梯度，反传到输入层时会得到一个与输入图像同大小、同通道数的梯度图，先对梯度取绝对值，而后对于每个像素，取 3 个通道上这个位置的最大值，将得到的图像作为灰度图进行可视化

这个方法的想法是，如果输入图像上某个位置的梯度值很大，说明这个位置像素值的改变更容易引起 class score 的变化，就代表模型更关注这块

![[CV/img/img19/image-5.png]]

甚至还可以根据得到的梯度图（称为 saliency map，代表模型对图像哪些位置的响应更显著），使用 graph cut 方法对原图进行裁剪

![[CV/img/img19/image-6.png]]

## Saliency via Guided Back Propagation

对上面的方法的一种改进，这个方法的目标是：可视化网络中任意一个神经元（比如某个中间层的某个通道，也可以是上一方法中的 class score 处）所关注的区域
- 选择网络中的一个神经元作为观察目标，而后从选定的地方出发，计算它对原始输入图像像素的梯度
- 在反传经过 ReLU 层时，只保留正梯度（相当于把原来前向过程的 relu 变成了反向的 relu ，经过这一过程，得到的结果一般更清晰、识别度更高）

![[CV/img/img19/image-7.png]]

## Class Activation Mapping (CAM)

CAM 的目标是：在不改变网络结构、不进行额外训练或反向传播的情况下，仅用一次前向传播，就生成一个指示关注区域的热力图

这个方法要求：模型最后必须采用下面的结构

![[CV/img/img19/image-8.png]]

在 global avg pooling 中，计算过程如下，其中 $f^k(i, j)$ 指 $f$ 的第 $k$ 个通道的特征图的 $(i,j)$ 处的值

$$
F_k = \frac{1}{H \times W} \sum_{i=1}^H \sum_{j=1}^W f^k(i, j)
$$

而后经过 FC 层，得到类别 $c$ 对应的分数，其中 $w^c$ 是 FC 层权重的第 $c$ 列，代表与第 $c$ 个类别相关的权重，而 $w^c_k$ 是 $w^c$ 的第 $k$ 行的元素

$$
\begin{align}
S_c &= \sum_{k=1}^K w_k^c \cdot F_k + b_c \\
&= \sum_{k=1}^K w_k^c \cdot \left( \frac{1}{H \times W} \sum_{i=1}^H \sum_{j=1}^W f^k(i, j) \right) + b_c \\
&= \frac{1}{H \times W} \sum_{i=1}^H \sum_{j=1}^W \sum_{k=1}^K w_k^c \cdot f^k(i, j) + b_c
\end{align}
$$

我们定义类别 $c$ 在位置 $(i, j)$ 的激活值 $M_c(i, j)$ 为

$$
M_c(i, j) = \sum_{k=1}^K w_k^c \cdot f^k(i, j)
$$

- 得到的图像大小与最后一个卷积层的特征图 $f$ 相同（$H \times W$）
- 它的计算方式是：对 $K$ 个特征图在位置 $(i, j)$ 的值进行加权求和，权重 $w_{k}^{c}$ 代表了特征图 $k$ 对于判断类别 $c$ 的重要程度
- $M_c(i, j)$ 值高的地方，就意味着那些对分类 $c$ 重要的特征图在该空间位置的激活值也很高，即图像的这个区域包含了更多与类别 $c$ 相关的特征
- 通常会对其进行 relu 操作，仅保留正向贡献

得到的图像一般会比输入图像小，需要通过上采样恢复为输入图像的大小

![[CV/img/img19/image-9.png]]

## Gradient-Weighted Class Activation Mapping (Grad-CAM)

对上面的方法的一种拓展，使用梯度计算重要性权重，不局限于模型结构，而且能对任一层计算热力图
- 先选取一层，其输出的特征图是 $A$ ，通过反向传播计算类别 $c$ 的 class score $S_c$ 关于 $A$ 的梯度 $\frac{\partial S_c}{\partial A}$ ，得到的梯度图大小和该特征图相同
- 通过 global avg pooling 得到重要性权重 $w_k$ ，使用与 CAM 相同的公式与方法得到热力图

![[CV/img/img19/image-10.png]]

# Visualization with Optimization

目标是得到一张使得某个类别分数最大的输入图像 $I$ ，定义如下的优化目标

$$\arg \max_I S_c(I) - \lambda \|I\|_2^2$$

- 将 $I$ 初始化为 0 ，因为模型通常是在中心化后的数据集上训练的
- 通过反传与梯度上升（因为目标是 argmax ，所以要沿着上升方向走）进行优化
- 最后加上训练集的平均值

这里最大化的是 softmax 之前的 class score ，因为 
- 如果最大化 $p_c=\text{softmax}(S_c)$ ，当 $p_c$ 接近 1 时，其梯度将会变得非常小
- softmax 存在相互抑制的效果，最大化 $p_c$ 可能通过抑制其它类别，而非增强目标类别的特征来实现

优化目标中还添加了正则化项，这是因为如果没有约束，优化可能会产生非常大的值，因为这样可以轻易提高 $S_c$ ，但这样的图像看起来很不自然

常见的正则化项有下面这几种
- L2 norm ：防止图像中出现某几个非常大的像素值主导结果
- Gaussian blur ：惩罚图像中的高频细节
- Clip pixels with small values / gradients to 0

![[CV/img/img19/image-11.png]]

## Adversarial Perturbations

考虑另一个目标：想要尽可能小的调整一个图像 $x$ ，使其被模型判断为另一个类别 $l$ ，设调整量为 $r$ ，可以最小化以下目标来求解（其中 $f$ 为模型）

$$\text{loss}(f(x + r), l) + c \cdot |r|$$

得到的结果很让人震惊，这个调整量往往比人们想象中的要小很多，小到人甚至看不出类别的改变，但是模型却判断成别的东西了，比如下面的图像中，右侧经过调整后的图像都被判断为了“鸵鸟”

![[CV/img/img19/image-12.png]]

甚至还存在一种通用的调整量，能把许多类别的事物，让模型判断成别的类别

![[CV/img/img19/image-13.png]]

## Deep Dream

与上面的目标相反，希望通过调整一个图像，来增加模型中某一层的响应，也可以定义一种类似的目标函数去优化

![[CV/img/img19/image-14.png]]

得到的结果就像做梦一样奇幻

![[CV/img/img19/image-15.png]]

## Feature Inversion

想要根据模型的某一层中提取的特征重建出一个输入图像
- 给定一个输入图像 $y$，通过前向传播得到其经过该层后的特征值 $\phi(y)$ 
- 通过优化一个目标函数，利用反向传播重建图像 $x'$ 

$$
x^* = \arg \min_x \|\phi(x) - \phi(y)\|^2
$$

- 目标是让重建图像 $x$ 在该层的特征与输入图像尽可能接近

![[CV/img/img19/image-16.png]]

可见在深层中，图像的语义内容和空间结构被保留了，但是颜色、纹理、具体形状变得很抽象

# Neural Texture Synthesis

想要根据一个图像，生成一个更大的连续纹理，要避免明显的重复拼接痕迹，还要保持全局上的随机性和自然感
- 基于最近邻的方法：像拼图一样，从参考纹理中一块一块地复制像素块，并粘贴到新图像上，同时确保块与块之间的边界过渡自然
- 基于统计度量的方法：当两种纹理在一些统计量上差不多时（比如在一系列线性滤波器中产生相似的响应时），它们通常很难区分
- 基于神经网络的方法：利用预训练好的网络（如 VGG ）提取特征，来衡量和匹配纹理的风格；本质上，它是对统计度量法的升级，用 **Gram矩阵**（衡量不同特征通道之间的相关性，这被证明与图像的纹理、风格高度相关）作为更强大的统计量

![[CV/img/img19/image-17.png]]

# Neural Style Transfer

想要把一个图像变成另一个图像的风格，即生成一个图像，具有图像 A 的内容，以及图像 B 的风格，为了达到这个目标，可以定义这样一个损失

$$
\mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{feat}} + \beta \mathcal{L}_{\text{style}} + \gamma \mathcal{L}_{\text{TV}}
$$

- $\mathcal{L}_{\text{feat}}$ 衡量生成图像的特征与内容图 A 的差异度
- $\mathcal{L}_{\text{style}}$ 衡量生成图像的风格与风格图 B 的差异度
- $\mathcal{L}_{\text{TV}}$ 是总变差正则化项，可选，让生成的图像看起来更自然，减小噪音
- 最关键的是 $\beta / \alpha$ ，它决定了生成的图像是更像内容图，还是更像风格图

那咋衡量一个图像的特征和风格呢？这正好可以用前面的 Feature inversion 与 Texture synthesis 部分的内容，为了得到特征向量，需要先搞一个预训练好的网络（如 VGG-19）
- 内容损失
	- 选取网络中较深的一层（因为深层特征捕捉的是物体的结构和布局）
	- 内容损失就是两个图像在这层的特征图之间的均方误差

$$
\mathcal{L}_{\text{feat}} = \lVert F^{(l)}(I) - F^{(l)}(I_A) \rVert^2
$$

- 风格损失
	- 选取网络中的多层（低层捕捉细节信息，高层捕捉纹理模式）
	- 对每一层，分别计算风格图和生成图特征图的 Gram矩阵
	- 风格损失是各层Gram矩阵之间的加权均方误差之和

$$
\mathcal{L}_{\text{style}} = \sum_l w_l \lVert G^{(l)}(I) - G^{(l)}(I_B) \rVert^2
$$

![[CV/img/img19/image-18.png]]

>编号 `relu5_1` 和 `conv5_1` 等，是 VGG 中的某层的命名方式，VGG 是由一堆 block 组成的，`conv 5_1` 就表示第 5 个 block 中的第 1 个卷积层；在这些工作中，一般使用 VGG 而非 ResNet 等更新的网络，是因为 VGG 的结构足够简单，效果还不错，其中结构简单指的是 VGG 层次分得很明确，而 ResNet 等残差网络，由于存在 res link ，导致某一处的特征图可能来自好几层，这就太乱了

除了前面提到的调整两种 loss 的超参数比例，调整风格图的大小也能带来不同的结果

![[CV/img/img19/image-19.png]]

## Fast Neural Style Transfer

Style Transfer 需要经过很多次 VGG 的前向 / 反向过程，才能让一坨噪声逐渐变成想要的图像，我们可以把最后生成的图像当作 ground truth，把风格图视为输入图像，训练一个神经网络，来直接把输入图像转换为目标风格

![[CV/img/img19/image-20.png]]

这里有一个值得注意的地方，就是这个训练的网络中使用 Batch Norm 效果会变差，这是因为 BN 是对 N,H,W 维度进行归一化的，问题就出在它对 batch 维度进行归一化
- 一个图像的风格是与网络中各个特征通道的特征图的分布（如均值和方差）相关的
- 在计算某个通道的均值时，BN 会聚合这个 Batch 内所有图片在这个通道上的值，这相当于把不同的风格强行混合、平均化了

所以这里使用 Instance Norm ，只对 H,W 维度归一化

![[CV/img/img19/image-21.png]]









