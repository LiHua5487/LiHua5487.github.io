
# Stereo System

回顾一下，相机标定可以求出相机参数，对极几何便于找到对应点，三角测量根据相机参数和对应点还原出世界坐标，双目视觉与三角测量类似，只不过是要根据双目图计算出点的深度，有了这一套流程，就可以进行三维重建

![[CV/img/img7/image.png]]

## Basic Stereo Matching Algorithm

将上述流程总结一下，可得下面一个基本的双目匹配算法（假设已经对相机进行标定）
- 对于一个图的每个像素，计算其对应的极线
- 在极线上找到最佳匹配点，作为对应点
- 根据对应点通过三角测量计算深度信息

![[CV/img/img7/image-1.png]]

## Stereo System

一个最简单的情况是两个相机平行放置，即相机高度相同且成像平面均与基线平行，这样极线就是水平的，而且可以进一步求得对应点在图像 $y$ 方向上的坐标是相同的

![[CV/img/img7/image-2.png]]

那么在进行对应点匹配时，只需要在 $y$ 坐标相等的水平线上找，即采用 scan line 的方式即可

---

对于一般情况，两个成像平面并不平行，可以先把两个成像平面投影变换到一个平行于基线的平面上，这称为 **立体矫正 Stereo Rectification** ，可以分解为以下过程

![[CV/img/img7/image-3.png]]

- 利用本质矩阵或基本矩阵计算出左相机到右相机的旋转变换 $R$ ，根据 $R^T$ 旋转右相机使得二者视角平行
- 应用一个旋转 $R_{\text{rect}}$ 使得成像平面与基线平行
- 用一个单应矩阵 $H$ 进一步调整，以减少相机畸变等失真

那怎么计算 $R_{\text{rect}}$ 呢？要让成像平面平行于基线，就等价于把极点变换到沿着基线方向的无穷远处

![[CV/img/img7/image-4.png]]

可以先用 SVD 或解方程 $Fe_1=0$ 的方式计算出 $e_1$ （齐次坐标表示），而后按照以下方法构造 $R_{\text{rect}}$

$$
\begin{align}
&\text{let } &&R_{\text{rect}} = 
\begin{pmatrix}
r_1, r_2, r_3
\end{pmatrix}^T\\
&\text{where } \ &&r_1 = \frac{e_1}{\|e_1\|}\\
&&& \ r_2 = \frac{[(0, 0, 1)^T]_{\times} r_1}{\|[(0, 0, 1)^T]_{\times} r_1\|}\\
&&& \ r_3 = r_1 \times r_2
\end{align}
$$

由于 $R_{\text{rect}}e_1=(\lVert e_1\rVert,0,0)^T$ ，这就代表着一个沿基线方向（前两个元素代表的向量与 $x$ 轴，即基线方向平行）的无穷远点（齐次坐标第三个元素为 0 ）

在立体矫正后，可以发现两个图上的极线都变为平行线，且处在同一 $y$ 坐标上了，这就变成了上面的简单情况，按照上面的方法进行匹配计算即可

![[CV/img/img7/image-5.png]]

## Disparity

在找到对应点后，怎么计算出深度呢？假设我们已经把相机变换为上述简单情况，深度的计算可以轻易的通过相似三角形来解决

![[CV/img/img7/image-6.png]]

![[CV/img/img7/image-7.png]]

可得深度计算公式为

$$z=\frac{fB}{x-x'}$$

- $f$ 为焦距 
- $B$ 为两个相机的基线距离
- $x$ 和 $x'$ 为图像平面内的水平坐标（单位 m ）

这里的 $x-x'$ 就对应着视差 disparity

$$disparity=u-u'=\frac{Bf}{z}$$

- 视差是针对于像素坐标而言的，如果最后想要求以 m 为单位的深度，要么把视差转换单位，要么使用以像素为单位的焦距 $f_X$ 
- 可见深度与视差成倒数关系，一般我们会先求出视差图，再转换为深度图，视差图可以看作一个中间载体

![[CV/img/img7/image-10.png]]

当两个相机离得较远时，视线交叉部分近似成正方形，三角测量时的误差更小；但由于离得远，视差比较大，对应点匹配时可能稍微困难一些

![[CV/img/img7/image-8.png]]

# Stereo Matching

## Local Stereo Matching

那具体咋在 scanline 上找一个点的最佳匹配位置呢？我们用一个滑窗去检测 scanline 上每一点的局部特征，并与该点比较，选出最值点，可以定义如下的公式去计算匹配度
- Sum of squared differences (SSD)

$$SSD(x, y, d) = \| w_L(x, y) - w_R(x - d, y) \|_2^2$$

- Zero Normalized Cross-Correlation (ZNCC), $\bar{w}$ is the mean of vector $w$ 

$$ZNCC(x, y, d) = \frac{(w_L(x, y) - \bar{w}_L(x, y))^T (w_R(x - d, y) - \bar{w}_R(x - d, y))}{\| w_L(x, y) - \bar{w}_L(x, y) \|_2 \| w_R(x - d, y) - \bar{w}_R(x - d, y) \|_2}$$

检测时，我们不用考虑整个 scanline ，由于 $z=\frac{fB}{x-x'}>0$ ，所以 $x>x'$ ，即由于视差存在，对于左图中的一个点，在右图中的对应点会偏左一些，只需要检测这个点的左边部分即可

![[CV/img/img7/image-9.png]]

总结一下，流程如下
- 先设置一个视差范围 $[0,D]$ 进行约束，减小匹配点的搜索范围
- 对于一个图里的每个像素，在另一个图找最佳匹配点
- 利用左图和右图分别可以得到两个视差图（左图像素在右图找对应点，和反过来），将二者进行比较，即如果左图中点 A 匹配到右图中的点 B ，那么从右图点 B 匹配回左图时，也应该得到点 A ，如果不一致就去掉这个 outlier 

![[CV/img/img7/image-11.png]]

但是得到的结果显然很不理想，在物体边缘处出现了很多黑色区域，这是由于存在 half occlusion 现象，即由于视差存在，一些区域可能左图能看见，右图看不见，或者反过来

应用更大的滑窗能让这个黑色区域更加平滑，但也会丢失一些细节

![[CV/img/img7/image-12.png]]

此外，上述匹配算法存在一个很严重的缺陷，对于一些重复出现的纹理，如果只关注局部，匹配时可能有多个位置相对应；更极端一点，如果表面没有纹理，那更匹配不上了，所以还需要考虑到全局特征，全局特征也能帮助恢复上面的黑色区域

## Global Stereo Matching

考虑利用全局特征来给匹配时添加一些约束，称为 Non-Local Constraints 
- Uniqueness ：一个点在另一个图至多只能有一个匹配点
- Ordering ：两个图中匹配点应该按相同的左右顺序出现
- Smoothness ：一般来讲，相邻的点应该有相似的视差值（当然对于物体边缘处等地方，深度本来就是不连续的，可以适当放宽这个约束）

### Disparity Space Image

找对应点时，对于左图的 scanline 上的一个像素，右图 scanline 上每个位置都对应着一个差异度，可以将其视为一种匹配的成本/代价

![[CV/img/img7/image-13.png]]

以左图的 scanline 为横轴，右图的 scanline 为纵轴，构建出这么一个图，上面的每个像素的值代表对于左图 scanline 的一个像素（横坐标），如果选取右图 scanline 上的一个像素（纵坐标）作为匹配点，对应的代价是多少（当然也可以解释为右图到左图，反正是对称的）

![[CV/img/img7/image-14.png]]

假设我们规定一个视差范围 $0\leq disparity\leq D$ ，那左图的每个像素只需与右图中一个局部范围上的像素进行匹配即可，其上的一条路径就代表 scanline 的匹配结果，我们的目标是找出一条总 cost 最小的路径，这代表着最优匹配方式

![[CV/img/img7/image-15.png]]

假设有这样一个匹配关系，先在图像上标记出匹配点，再把它们连起来，得到这样一个路径，可以发现：如果对应位置匹配，就斜着走；如果左 scanline 被跳过了，就横着走；如果右 scanline 被跳过了，就竖着走

![[CV/img/img7/image-16.png]]

![[CV/img/img7/image-17.png]]

>这个图是让豆包把黑板板书变成黑白风格的，AI 还是太好用了

要找到一个总代价最小的路径，这可以利用动态规划实现，维护一个 dp 表 $C(i,j)$ ，表示到达位置 $(i,j)$ 的最小总代价

考虑状态转移方程，对于一个位置，要么是从上面过来的，要么是从左边过来的，要么是从左上方过来的，这里我们分为两种情况
- 如果对应像素匹配，即是从左上方过来的，就加上其匹配代价 $e(i,j)$ 
- 如果跳过了一个像素（occluded，这种情况一般是 half occlusion 导致的），即是从左边或者上面过来的，就加上一个跳过的代价 `occlusionConstant` ，一般设为一个比较大的常量

```
C(i,j) = min([
	C(i-1,j-1) + e(i,j),
	C(i-1,j) + occlusionConstant,
	C(i,j-1) + occlusionConstant, ])
```

在确定路径时，可以进行回溯，通过比较变化量，推断当前位置是从哪里转移过来的；也可以在前向计算时就记录下来

![[CV/img/img7/image-18.png]]

可以发现采用这种方式后，效果好了一些，但还是有较明显的黑色区域，这是因为我们只是简单的将半遮挡区域设为黑的

![[CV/img/img7/image-19.png]]

但实际上我们知道哪些像素是被半遮挡的，可以根据周围的像素进行填充，对于左图中的像素，就在其左边找到最近的未被遮挡的像素，把它的值复制过来；对于右图的像素就从右边找

![[CV/img/img7/image-20.png]]

效果好了很多，内部的黑色区域基本上没了，但是会有横向的条纹

![[CV/img/img7/image-21.png]]

### DP in Resizing and Warping

除了视差图的构建，动态规划还能用于图像缩放和变形，在图像缩放时，如果直接进行拉伸或压缩，会导致里边的东西都变形了，Seam Carving 的想法是通过删除或复制重要性（可以定义一个 energy 函数来计算）比较低的路径（一个宽度为 1 的缝），来实现图像的缩放变形，这可以利用 dp 来求解

![[CV/img/img7/image-22.png]]

在拼接多张图像时，dp 可以用于寻找最优路径，以最小化图像之间的失真或缝隙；而在图像变形的场景中，特别是在处理特征点的匹配和变形时，可以用 dp 来确保特征点之间最小的变形变化，下图为把一个直接拼贴得到的不规则全景图变为矩形

![[CV/img/img7/image-23.png]]

### Global Optimization / Deep Learning

回到正题，上面的 DSI 是对每个 scanline 分别处理的，并不是真正的全局，对于一个深度图 $d$ ，我们可以定义一个 energy 函数，其包含两项
- 数据项：衡量在深度值对应的视差下，图像中的像素与其对应点的匹配程度
- 光滑项：鼓励深度图在空间上平滑变化，即相邻像素的深度值应该相似

![[CV/img/img7/image-24.png]]

可以利用 graph cuts 等算法来最小化这种形式的能量函数，此外，还可以利用之前讲过的 Joint Bilateral Upsampling 方法，先降采样再升采样以加速计算

---

当然还可以利用深度学习的方法来预测深度图，训练时，提供一组双目图，将左图输入到网络去预测一个反向深度图（视差图），结合这个预测的反向深度图与输入对应的右图，能还原出一个左图，把它和输入的左图进行比较，作为误差

![[CV/img/img7/image-25.png]]






