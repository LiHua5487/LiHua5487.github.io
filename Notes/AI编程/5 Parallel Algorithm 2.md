
# Sort

## Brick Sort

一种最基本的排序算法是冒泡排序，其时间复杂度是 $O(n^2)$ ，在 GPU 上，可以每一步都把数组中的元素两两比较，下一步错位后继续这么比较，由于画出来像砖头摞在一块，所以称为 Brick Sort ，其 work complexity 是 $O(n^2)$ ，step complexity 是 $O(n)$ 

![[AI编程/imgs/img5/image.png]]

>由于一个从小到大排好序的数组，每两个相邻元素都是左小于右的，而 brick sort 每一步干的事就是尽可能消除不符的情况，所以能保证正确性

## Merge Sort

归并排序的想法是，把一个数组劈成两半，分别进行排序（仍然使用归并排序，递归的进行），而后把这两个排好序的数组合并到一块

在合并时，由于两个数组各自都是排好序的，只需比较二者头部元素的大小，依次取出即可，每次合并是 $O(n)$ ，而递归的将数组二分共有 $\text{log}n$ 级别的步数，所以总的时间复杂度是 $O(n\text{log}n)$ 

![[AI编程/imgs/img5/image-1.png]]

但是在 GPU 上，为了简化每个 core 的运算，没有递归这种东西（不然还得搞函数堆栈），所以我们自底向上进行合并，每个线程负责一个合并，但这有个问题，当两个数组很长时，直接按照串行的方法合并会导致耗时过长，此时需要一个 block 负责一个合并，再往上就得多个 block 负责一个合并，所以按照数组长度，我们需要 3 种合并算法

---

对于一个线程进行合并，直接按串行方法处理即可；对于一个 block 进行合并，可以这么想：要把两个数组合并，就是要找到每个元素在合并后的数组中处在什么位置，而对于一个排好序的数组，其位置取决于有多少个元素大于/小于它，对于一个数，我们只需求出两个数组中小于它的数的个数，就能确定其位置

在这个数所处的数组中，由于这个数组排好序了，小于它的数的个数能根据其下标确定，只需在另一个数组中按顺序比较即可

![[AI编程/imgs/img5/image-2.png]]

比如图中数组，要找到 List1 中的 7 合并后的位置，其下标为 2 ，说明 List1 中有 2 个数比它小，而后在 List2 中从左往右进行比较，发现首个大于它的数是 8 ，下标为 2 ，说明 List2 中有 2 个数比它小，则 7 的最终下标就是 2+2=4

---

对于多个 block 进行合并，由于不同 block 之间的共享内存是独立的，所以考虑将数组进行分段合并，这里有一个很巧妙的分段思路：在两个数组中先取一些标记点，比较这些标记点的大小，按照大小顺序把一个数组中的一个标记点对应到另一个数组的两个标记点之间，这可以形成一堆连线，由于是按大小顺序进行的，这些连线并不会交叉，那么就可以按照这些连线把两个数组分为若干段，每个 block 负责其中对应的区间的合并，最后把所有 block 的结果连起来就行

![[AI编程/imgs/img5/image-3.png]]

但是上述算法并没有过多的减少时间复杂度，因为在合并过程中都需要一定程度上的遍历比较

## Sorting Network

sorting network 是对排序算法的图形化表述，一个基本的二元比较可以表述为以下形式：输入 x 和 y ，输出时把小的放上面，把大的放下面，可以把这个比较器用一个竖线表示，而横线则代表数组中的一个位置上的数据

![[AI编程/imgs/img5/image-4.png]]

一个排序算法就可以表示成一堆横向中间连着一堆竖线的组合，为了衡量其运行时间，引入 depth 的概念，每个比较器对应一个 depth ，表示要得出这一步的比较结果，需要进行几次运算，即取两个数据线上的更大的一个 depth 并 +1 

$$\text{depth}=\text{max}(dx,dy)+1$$

>dx 和 dy 分别表示输入数据 x 和 y 要 dx 和 dy 步才能算出来，为了比较二者，需要等它们都算完才能比，所以取最大值，而后 +1 表示把二者进行了一次比较

![[AI编程/imgs/img5/image-5.png]]

那么整个网络的 depth 就是所有比较器的最大的 depth ，相同 depth 的比较可以同时进行，而不同 depth 的比较得串行进行

可以发现，冒泡排序和插入排序的并行化表示是一样的，而 Brick Sort 是更为保守的并行化的冒泡排序（每一列都会多出几条竖线）

![[AI编程/imgs/img5/image-6.png]]

### Bitonic Sorting Network

**bitonic sequence 双调序列** ：一个先递增再递减的数组（或者其循环移动后的数组，要么有个尖，要么有个坑，要么一个尖一个坑），与单调序列对应

为了检验一个排序网络能不能 work ，可以穷举 $1,2,...,n$ 的全排列输入进去，看输出结果是不是都是对的，对于长度为 $n$ 的输入，共有 $n!$ 种

但实际上，我们只需要测试一串 0-1 序列的全排列即可，这就是 **0-1原理** ，要证明这个命题，等价于证明其逆否命题：”如果一个排序网络不能对所有序列正确排序，则存在一个 0-1 序列使得其不能正确排序“

以升序排序为例，如果有一个不能正确排序的序列，则其排序结果中必然可以找到一个逆序对 $(a,b)$ ，其中 $a>b$ ，那么我们对输入序列做二值化操作，阈值设为 a （大于等于 a 的设为 1 ，小于的设为 0 ），得到一个 0-1 序列，由于相对大小没变，所以排序网络进行的交换与否的操作也没变（若输入的两数相同，既可以视为交换，也可以视为没交换，那还是可以视为与原来的操作相同），所以在原来的逆序对的位置还会存在一个逆序对 $(1,0)$ ，这仍然是不对的

由于我们只需要遍历 0-1 序列，有 $2^n$ 种排列方式，这个数量就小了很多，这不只是在测试时有用，我们还可以用这个思路来构建一个排序网络，比如前面的归并排序

---

先考虑一个基本单元 **Half-Cleaner** ，对于输入的 bitonic 0-1 序列，可以变为一个 bitonic 0-1 序列和一个单纯由 0 或 1 组成的序列（这部分是排好序的）

![[AI编程/imgs/img5/image-7.png]]

如果我们对这两个序列继续使用 Half-Cleaner ，递归的进行下去，最终就可以得到一个排序好的序列，我们把这样一个递归单元定义为 **Bitonic Sorter** ，其 depth 是 $\text{log}n$ 级别的

![[AI编程/imgs/img5/image-8.png]]

对于两个排好序的序列，可以利用下面的单元变成一个 bitonic 序列和一个单纯由 0 或 1 组成的序列

![[AI编程/imgs/img5/image-9.png]]

那么归并操作就可以变成：先把两个输入序列变为 bitonic 序列，再分别利用 Bitonic Sorter 排序，变为一个排好序的序列，这个结构被称为 **Merger**

![[AI编程/imgs/img5/image-10.png]]

对于一个没有排序的序列，就可以从两个相邻元素开始，逐步应用 Merger 进行排序与合并，最后就能得到一个排好序的序列，这就是 **Merging Network**

![[AI编程/imgs/img5/image-11.png]]

归并操作进行的次数也是 $\text{log}n$ 级别的，那这个网络的 step complexity 就是 $O(\text{log}^2n)$ 的，值得注意的是这比 $O(n)$ 还要快，因为洛必达可得

$$\lim_{x \to \infty}\frac{\text{log}^2n}{n}=0$$

## Radix Sort

如果要排序的数都是整数，可以使用 Radix Sort 基数排序 ，从后往前按位进行排序（从前往后会出问题，比如 100 和 001 ，如果最后进行最后一位的比较，会导致 001 排在 100 后面，这显然不对）

>基数：数据在每一位上的可能取值数量，比如 10 进制的基数是 10 ，英文字符串的基数是 26 

实际上，可以先把数据转换为 2 进制，这样在每一位的比较时，就可以利用 compact 操作，比如要排序 `0,1,0,1,1,1,0,0` ，只需进行 exclusive scan ，得到前缀和 `[0,0,1,1,2,3,4,4]` ，这样就能把 1 全选出来放到一个数组里，前面再填上 0 即可，这个操作的时间复杂度是 $O(\text{log}n)$

![[AI编程/imgs/img5/image-12.png]]

# Stream

把 GPU 视为一个工厂，stream 就好比工厂中的流水线，一个工厂可以开很多流水线，但一个流水线上必须按照顺序执行任务

在 CUDA 中，核函数默认会使用 `stream 0` ，所以如果不手动指定，这些核函数都是顺序执行的，即必须等上一个执行完了才能执行下一个，这很影响效率

为此，可以声明两个 stream ，把两个核函数放到不同 stream 运行，这样两个核函数就是异步的了，但要注意，默认流 `stream 0` 仍会阻塞其它流

同时，使用 `cudaMemcpyAsync` 可以让数据传输和其它 CPU 函数异步执行，但由于其与核函数在一个 stream 里，它们还是顺序执行的

```cpp
cudaStream_t stream1, stream2;
cudaStreamCreate(&stream1);
cudaStreamCreate(&stream2);

// 流1：拷贝数据1 → 内核1 → 回传数据1
cudaMemcpyAsync(din1, hin1, size, H2D, stream1);
kernel1<<<blocks, threads, 0, stream1>>>(dev_data1);
cudaMemcpyAsync(hout1, dout1, size, D2H, stream1);

// 流2：拷贝数据2 → 内核2 → 回传数据2
cudaMemcpyAsync(din2, hin2, size, H2D, stream2);
kernel2<<<blocks, threads, 0, stream2>>>(dev_data2);
cudaMemcpyAsync(hout2, dout2, size, D2H, stream2);

// 默认流，会等待stream1和stream2完成
kernel3<<<blocks, threads>>>();

cudaStreamDestroy(stream1);
cudaStreamDestroy(stream2);
```

还可以进一步改进，让核函数和数据传输也是异步的，即算完一部分就传输一部分，而不是全算完再统一传输

![[AI编程/imgs/img5/image-13.png]]

关于 Synchronize ，可以细分为以下几种

全设备同步
- `cudaDeviceSynchronize()` ：阻塞主机线程，直到所有设备上的 CUDA 任务（核函数和数据拷贝）都完成

针对特定流的同步
- `cudaStreamSynchronize(stream)` ：阻塞主机线程，直到指定流上的所有 CUDA 任务完成

基于事件的同步
- `cudaEventRecord(event, stream)`：在指定流中记录一个事件
- `cudaStreamWaitEvent(stream, event)` ：指定流中的后续操作需等待某事件完成后才能继续执行
- `cudaEventQuery(event)` ：检查事件是否已经完成，非阻塞


























